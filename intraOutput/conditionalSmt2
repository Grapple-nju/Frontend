<org.apache.hadoop.hbase.avro.AvroUtil: void <init>()>
0:#p

<org.apache.hadoop.hbase.avro.generated.AAlreadyExists: void <init>()>
0:#p

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: int addScanner(org.apache.hadoop.hbase.client.ResultScanner)>
0:#r#$I$@var$stack3
0:#p#$R$@para0

<org.apache.hadoop.hbase.avro.AvroServer: void <init>()>
0:#p

<org.apache.hadoop.hbase.avro.AvroUtil: org.apache.hadoop.hbase.avro.generated.AServerAddress hsaToASA(org.apache.hadoop.hbase.HServerAddress)>
0:#r#$R$0
0:#p#$R$@para0

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: org.apache.hadoop.hbase.client.ResultScanner getScanner(int)>
0:#r#$R$@ret1
0:#p#$I$@para0

<org.apache.hadoop.hbase.avro.generated.AAlreadyExists: org.apache.avro.Schema getSchema()>
0:#r#$R$@var$stack1
0:#p

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: org.apache.hadoop.hbase.client.ResultScanner removeScanner(int)>
0:#r#$R$@ret1
0:#p#$I$@para0

<org.apache.hadoop.hbase.avro.AvroUtil: org.apache.hadoop.hbase.avro.generated.ARegionLoad hrlToARL(org.apache.hadoop.hbase.HServerLoad$RegionLoad)>
0:#r#$R$3
0:#p#$R$@para0

<org.apache.hadoop.hbase.avro.generated.AAlreadyExists: java.lang.Object get(int)>
0:(= $I$@para0 0)
0:#p#$I$@para0
2:#r#$R$@var$stack2

<org.apache.hadoop.hbase.avro.AvroServer: void printUsageAndExit()>
0:#p

<org.apache.hadoop.hbase.avro.AvroUtil: org.apache.hadoop.hbase.avro.generated.AServerLoad hslToASL(org.apache.hadoop.hbase.HServerLoad)>
0:(= $R$@ret6 soot.jimple.NullConstant@965450422)
0:#c#null#<org.apache.hadoop.hbase.avro.generated.AServerLoad: void <init>()>
0:#c#null#<org.apache.hadoop.hbase.HServerLoad: int getLoad()>
0:#c#null#<org.apache.hadoop.hbase.HServerLoad: int getMaxHeapMB()>
0:#c#null#<org.apache.hadoop.hbase.HServerLoad: int getMemStoreSizeInMB()>
0:#c#null#<org.apache.hadoop.hbase.HServerLoad: int getNumberOfRegions()>
0:#c#null#<org.apache.hadoop.hbase.HServerLoad: int getNumberOfRequests()>
0:#c#null#<org.apache.hadoop.hbase.HServerLoad: java.util.Collection getRegionsLoad()>
0:#c#null#<org.apache.avro.Schema: org.apache.avro.Schema createArray(org.apache.avro.Schema)>#$R$@var$stack14
0:#p#$R$@para0
1:(not $Z$@ret3)
1:#c#null#<java.util.Collection: int size()>
1:#c#null#<org.apache.avro.generic.GenericData$Array: void <init>(int,org.apache.avro.Schema)>#$I$@ret0#$R$@ret7
1:#c#null#<java.util.Collection: java.util.Iterator iterator()>
1:#c#null#<java.util.Iterator: boolean hasNext()>
3:#r#$R$5
4:#r#$R$5
2:#r#$R$5

<org.apache.hadoop.hbase.avro.AvroUtil: org.apache.hadoop.hbase.avro.generated.AServerInfo hsiToASI(org.apache.hadoop.hbase.HServerInfo)>
0:#r#$R$9
0:#p#$R$@para0

<org.apache.hadoop.hbase.avro.generated.AAlreadyExists: void put(int,java.lang.Object)>
0:(= $I$@para0 0)
0:#p#$I$@para0#$R$@para1

<org.apache.hadoop.hbase.avro.AvroServer: void printUsageAndExit(java.lang.String)>
0:(= $R$@para0 soot.jimple.NullConstant@965450422)
0:#p#$R$@para0

<org.apache.hadoop.hbase.avro.generated.AAlreadyExists: void <clinit>()>
0:#p

<org.apache.hadoop.hbase.avro.generated.AClusterStatus: void <init>()>
0:#p

<org.apache.hadoop.hbase.avro.generated.AClusterStatus: org.apache.avro.Schema getSchema()>
0:#r#$R$@var$stack1
0:#p

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: void <init>()>
0:#p

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: void <init>(org.apache.hadoop.conf.Configuration)>
0:#p#$R$@para0

<org.apache.hadoop.hbase.avro.generated.AClusterStatus: java.lang.Object get(int)>
0:(= $I$@para0 0)
0:#p#$I$@para0
1:(= $I$@para0 1)
3:(= $I$@para0 2)
7:(= $I$@para0 3)
15:(= $I$@para0 4)
31:(= $I$@para0 5)
63:(= $I$@para0 6)
127:(= $I$@para0 7)
256:#r#$R$@ret0
128:#r#$R$@var$stack6
64:#r#$R$@ret0
32:#r#$R$@ret0
16:#r#$R$@var$stack11
8:#r#$R$@ret0
4:#r#$R$@var$stack14
2:#r#$R$@ret0

<org.apache.hadoop.hbase.avro.generated.AClusterStatus: void put(int,java.lang.Object)>
0:(= $I$@para0 0)
0:#p#$I$@para0#$R$@para1
1:(= $I$@para0 1)
3:(= $I$@para0 2)
7:(= $I$@para0 3)
15:(= $I$@para0 4)
31:(= $I$@para0 5)
63:(= $I$@para0 6)
127:(= $I$@para0 7)

<org.apache.hadoop.hbase.avro.generated.AClusterStatus: void <clinit>()>
0:#p

<org.apache.hadoop.hbase.avro.generated.AColumn: void <init>()>
0:#p

<org.apache.hadoop.hbase.avro.generated.AColumn: org.apache.avro.Schema getSchema()>
0:#r#$R$@var$stack1
0:#p

<org.apache.hadoop.hbase.avro.AvroServer: void doMain(java.lang.String[])>
0:(>= $I$@var$stack7 1)
0:#p#$R$@para0
1:(>= 0 $I$@varlen$)
1:#c#null#<org.apache.hadoop.hbase.avro.AvroServer: void printUsageAndExit()>
3:(not $Z$@ret0)
3:#c#null#<java.lang.String: boolean startsWith(java.lang.String)>#soot.jimple.StringConstant@1156839878
8:$Z$@ret0
8:#c#null#<java.lang.String: boolean equals(java.lang.Object)>#soot.jimple.StringConstant@467989306
17:(not $Z$@ret0)
17:#c#null#<java.lang.String: boolean equals(java.lang.Object)>#soot.jimple.StringConstant@2000600715
36:(not $Z$@ret0)
36:#c#null#<java.lang.String: boolean equals(java.lang.Object)>#soot.jimple.StringConstant@562395037
74:(not $Z$@ret0)
74:#c#null#<java.lang.String: boolean equals(java.lang.Object)>#soot.jimple.StringConstant@2061731746
2:(>= 0 $I$@varlen$)
5:(not $Z$@ret0)
5:#c#null#<java.lang.String: boolean startsWith(java.lang.String)>#soot.jimple.StringConstant@1156839878
12:$Z$@ret0
12:#c#null#<java.lang.String: boolean equals(java.lang.Object)>#soot.jimple.StringConstant@467989306
25:(not $Z$@ret0)
25:#c#null#<java.lang.String: boolean equals(java.lang.Object)>#soot.jimple.StringConstant@2000600715
52:(not $Z$@ret0)
52:#c#null#<java.lang.String: boolean equals(java.lang.Object)>#soot.jimple.StringConstant@562395037
106:(not $Z$@ret0)
106:#c#null#<java.lang.String: boolean equals(java.lang.Object)>#soot.jimple.StringConstant@2061731746

<org.apache.hadoop.hbase.avro.generated.AColumn: java.lang.Object get(int)>
0:(= $I$@para0 0)
0:#p#$I$@para0
1:(= $I$@para0 1)
4:#r#$R$@var$stack2
2:#r#$R$@var$stack3

<org.apache.hadoop.hbase.avro.AvroServer: void main(java.lang.String[])>
0:#p#$R$@para0

<org.apache.hadoop.hbase.avro.generated.AColumn: void put(int,java.lang.Object)>
0:(= $I$@para0 0)
0:#p#$I$@para0#$R$@para1
1:(= $I$@para0 1)

<org.apache.hadoop.hbase.avro.generated.AColumnFamilyDescriptor: void <init>()>
0:#p

<org.apache.hadoop.hbase.avro.generated.AColumnFamilyDescriptor: org.apache.avro.Schema getSchema()>
0:#r#$R$@var$stack1
0:#p

<org.apache.hadoop.hbase.avro.generated.AColumnFamilyDescriptor: java.lang.Object get(int)>
0:(= $I$@para0 0)
0:#p#$I$@para0
1:(= $I$@para0 1)
3:(= $I$@para0 2)
7:(= $I$@para0 3)
15:(= $I$@para0 4)
31:(= $I$@para0 5)
63:(= $I$@para0 6)
127:(= $I$@para0 7)
256:#r#$R$@ret0
128:#r#$R$@ret0
64:#r#$R$@ret0
32:#r#$R$@ret0
16:#r#$R$@ret0
8:#r#$R$@ret0
4:#r#$R$@var$stack15
2:#r#$R$@var$stack2

<org.apache.hadoop.hbase.avro.AvroUtil: org.apache.hadoop.hbase.avro.generated.AClusterStatus csToACS(org.apache.hadoop.hbase.ClusterStatus)>
0:(= $R$@ret2 soot.jimple.NullConstant@965450422)
0:#c#null#<org.apache.hadoop.hbase.avro.generated.AClusterStatus: void <init>()>
0:#c#null#<org.apache.hadoop.hbase.ClusterStatus: double getAverageLoad()>
0:#c#null#<org.apache.hadoop.hbase.ClusterStatus: java.util.Collection getDeadServerNames()>
0:#c#null#<org.apache.avro.Schema: org.apache.avro.Schema create(org.apache.avro.Schema$Type)>#$R$@var$stack13
0:#c#null#<org.apache.avro.Schema: org.apache.avro.Schema createArray(org.apache.avro.Schema)>#$R$@ret3
0:#p#$R$@para0
1:(not $Z$@ret3)
1:#c#null#<java.util.Collection: int size()>
1:#c#null#<org.apache.avro.generic.GenericData$Array: void <init>(int,org.apache.avro.Schema)>#$I$@ret0#$R$@ret4
1:#c#null#<java.util.Collection: java.util.Iterator iterator()>
1:#c#null#<java.util.Iterator: boolean hasNext()>
3:(= $R$@ret8 soot.jimple.NullConstant@965450422)
3:#c#null#<java.util.Iterator: java.lang.Object next()>
3:#c#null#<org.apache.avro.util.Utf8: void <init>(java.lang.String)>#$R$@ret0
3:#c#null#<org.apache.avro.generic.GenericData$Array: void add(java.lang.Object)>#$R$13
3:#c#null#<org.apache.hadoop.hbase.ClusterStatus: int getDeadServers()>
3:#c#null#<org.apache.hadoop.hbase.ClusterStatus: java.lang.String getHBaseVersion()>
3:#c#null#<org.apache.avro.util.Utf8: void <init>(java.lang.String)>#$R$@ret4
3:#c#null#<org.apache.hadoop.hbase.ClusterStatus: int getRegionsCount()>
3:#c#null#<org.apache.hadoop.hbase.ClusterStatus: int getRequestsCount()>
3:#c#null#<org.apache.hadoop.hbase.ClusterStatus: java.util.Collection getServerInfo()>
3:#c#null#<org.apache.avro.Schema: org.apache.avro.Schema createArray(org.apache.avro.Schema)>#$R$@var$stack23
7:(not $Z$@ret3)
7:#c#null#<java.util.Collection: int size()>
7:#c#null#<org.apache.avro.generic.GenericData$Array: void <init>(int,org.apache.avro.Schema)>#$I$@ret0#$R$@ret9
7:#c#null#<java.util.Collection: java.util.Iterator iterator()>
7:#c#null#<java.util.Iterator: boolean hasNext()>
15:#r#$R$11
16:#r#$R$11
8:#r#$R$11
4:(= $R$@ret5 soot.jimple.NullConstant@965450422)
4:#c#null#<org.apache.hadoop.hbase.ClusterStatus: int getDeadServers()>
4:#c#null#<org.apache.hadoop.hbase.ClusterStatus: java.lang.String getHBaseVersion()>
4:#c#null#<org.apache.avro.util.Utf8: void <init>(java.lang.String)>#$R$@ret1
4:#c#null#<org.apache.hadoop.hbase.ClusterStatus: int getRegionsCount()>
4:#c#null#<org.apache.hadoop.hbase.ClusterStatus: int getRequestsCount()>
4:#c#null#<org.apache.hadoop.hbase.ClusterStatus: java.util.Collection getServerInfo()>
4:#c#null#<org.apache.avro.Schema: org.apache.avro.Schema createArray(org.apache.avro.Schema)>#$R$@var$stack23
9:(not $Z$@ret3)
9:#c#null#<java.util.Collection: int size()>
9:#c#null#<org.apache.avro.generic.GenericData$Array: void <init>(int,org.apache.avro.Schema)>#$I$@ret0#$R$@ret6
9:#c#null#<java.util.Collection: java.util.Iterator iterator()>
9:#c#null#<java.util.Iterator: boolean hasNext()>
19:#r#$R$11
20:#r#$R$11
10:#r#$R$11
2:(= $R$@ret6 soot.jimple.NullConstant@965450422)
2:#c#null#<org.apache.avro.generic.GenericData$Array: void <init>(int,org.apache.avro.Schema)>#0#$R$@ret4
2:#c#null#<org.apache.hadoop.hbase.ClusterStatus: int getDeadServers()>
2:#c#null#<org.apache.hadoop.hbase.ClusterStatus: java.lang.String getHBaseVersion()>
2:#c#null#<org.apache.avro.util.Utf8: void <init>(java.lang.String)>#$R$@ret2
2:#c#null#<org.apache.hadoop.hbase.ClusterStatus: int getRegionsCount()>
2:#c#null#<org.apache.hadoop.hbase.ClusterStatus: int getRequestsCount()>
2:#c#null#<org.apache.hadoop.hbase.ClusterStatus: java.util.Collection getServerInfo()>
2:#c#null#<org.apache.avro.Schema: org.apache.avro.Schema createArray(org.apache.avro.Schema)>#$R$@var$stack23
5:(not $Z$@ret3)
5:#c#null#<java.util.Collection: int size()>
5:#c#null#<org.apache.avro.generic.GenericData$Array: void <init>(int,org.apache.avro.Schema)>#$I$@ret0#$R$@ret7
5:#c#null#<java.util.Collection: java.util.Iterator iterator()>
5:#c#null#<java.util.Iterator: boolean hasNext()>
11:#r#$R$11
12:#r#$R$11
6:#r#$R$11

<org.apache.hadoop.hbase.avro.generated.AColumnFamilyDescriptor: void put(int,java.lang.Object)>
0:(= $I$@para0 0)
0:#p#$I$@para0#$R$@para1
1:(= $I$@para0 1)
3:(= $I$@para0 2)
7:(= $I$@para0 3)
15:(= $I$@para0 4)
31:(= $I$@para0 5)
63:(= $I$@para0 6)
127:(= $I$@para0 7)

<org.apache.hadoop.hbase.avro.AvroUtil: org.apache.hadoop.hbase.avro.generated.ATableDescriptor htdToATD(org.apache.hadoop.hbase.HTableDescriptor)>
0:(<= $I$@ret5 0)
0:#c#null#<org.apache.hadoop.hbase.avro.generated.ATableDescriptor: void <init>()>
0:#c#null#<org.apache.hadoop.hbase.HTableDescriptor: byte[] getName()>
0:#c#null#<java.nio.ByteBuffer: java.nio.ByteBuffer wrap(byte[])>#$R$@ret1
0:#c#null#<org.apache.hadoop.hbase.HTableDescriptor: java.util.Collection getFamilies()>
0:#c#null#<org.apache.avro.Schema: org.apache.avro.Schema createArray(org.apache.avro.Schema)>#$R$@var$stack12
0:#c#null#<java.util.Collection: int size()>
0:#p#$R$@para0
1:(not $Z$@ret3)
1:#c#null#<java.util.Collection: int size()>
1:#c#null#<org.apache.avro.generic.GenericData$Array: void <init>(int,org.apache.avro.Schema)>#$I$@ret0#$R$@ret4
1:#c#null#<java.util.Collection: java.util.Iterator iterator()>
1:#c#null#<java.util.Iterator: boolean hasNext()>
3:#r#$R$89
4:#r#$R$89
2:#r#$R$89

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: org.apache.avro.util.Utf8 getHBaseVersion()>
0:#r#$R$54
0:#p

<org.apache.hadoop.hbase.avro.generated.AColumn: void <clinit>()>
0:#p

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: org.apache.hadoop.hbase.avro.generated.AClusterStatus getClusterStatus()>
0:#r#$R$@ret1
0:#p

<org.apache.hadoop.hbase.avro.generated.AColumnValue: void <init>()>
0:#p

<org.apache.hadoop.hbase.avro.generated.AColumnValue: org.apache.avro.Schema getSchema()>
0:#r#$R$@var$stack1
0:#p

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: org.apache.avro.generic.GenericArray listTables()>
0:(>= 0 $I$@varlen$)
0:#c#null#<org.apache.hadoop.hbase.client.HBaseAdmin: org.apache.hadoop.hbase.HTableDescriptor[] listTables()>
0:#c#null#<org.apache.avro.Schema: org.apache.avro.Schema createArray(org.apache.avro.Schema)>#$R$@var$stack10
0:#c#null#<org.apache.avro.generic.GenericData$Array: void <init>(int,org.apache.avro.Schema)>#$I$@var$stack13#$R$@ret1
0:#p
2:#r#$R$96

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: org.apache.hadoop.hbase.avro.generated.ATableDescriptor describeTable(java.nio.ByteBuffer)>
0:#r#$R$@ret2
0:#p#$R$@para0

<org.apache.hadoop.hbase.avro.generated.AColumnValue: java.lang.Object get(int)>
0:(= $I$@para0 0)
0:#p#$I$@para0
1:(= $I$@para0 1)
3:(= $I$@para0 2)
7:(= $I$@para0 3)
16:#r#$R$@var$stack3
8:#r#$R$@var$stack4
4:#r#$R$@var$stack5
2:#r#$R$@var$stack2

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: boolean isTableEnabled(java.nio.ByteBuffer)>
0:#r#$Z$@ret1
0:#p#$R$@para0

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: boolean tableExists(java.nio.ByteBuffer)>
0:#r#$Z$@ret1
0:#p#$R$@para0

<org.apache.hadoop.hbase.avro.generated.AColumnValue: void put(int,java.lang.Object)>
0:(= $I$@para0 0)
0:#p#$I$@para0#$R$@para1
1:(= $I$@para0 1)
3:(= $I$@para0 2)
7:(= $I$@para0 3)

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: org.apache.hadoop.hbase.avro.generated.AFamilyDescriptor describeFamily(java.nio.ByteBuffer,java.nio.ByteBuffer)>
0:#r#$R$@ret4
0:#p#$R$@para0#$R$@para1

<org.apache.hadoop.hbase.avro.generated.AColumnValue: void <clinit>()>
0:#p

<org.apache.hadoop.hbase.avro.generated.ACompressionAlgorithm: org.apache.hadoop.hbase.avro.generated.ACompressionAlgorithm[] values()>
0:#r#$R$@ret0
0:#p

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: java.lang.Void createTable(org.apache.hadoop.hbase.avro.generated.ATableDescriptor)>
0:#r#soot.jimple.NullConstant@965450422
0:#p#$R$@para0

<org.apache.hadoop.hbase.avro.generated.ACompressionAlgorithm: org.apache.hadoop.hbase.avro.generated.ACompressionAlgorithm valueOf(java.lang.String)>
0:#r#$R$@ret0
0:#p#$R$@para0

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: java.lang.Void deleteTable(java.nio.ByteBuffer)>
0:#r#soot.jimple.NullConstant@965450422
0:#p#$R$@para0

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: java.lang.Void modifyTable(java.nio.ByteBuffer,org.apache.hadoop.hbase.avro.generated.ATableDescriptor)>
0:#r#soot.jimple.NullConstant@965450422
0:#p#$R$@para0#$R$@para1

<org.apache.hadoop.hbase.avro.generated.AColumnFamilyDescriptor: void <clinit>()>
0:#p

<org.apache.hadoop.hbase.avro.generated.ADelete: void <init>()>
0:#p

<org.apache.hadoop.hbase.avro.generated.ADelete: org.apache.avro.Schema getSchema()>
0:#r#$R$@var$stack1
0:#p

<org.apache.hadoop.hbase.avro.generated.ACompressionAlgorithm: void <init>(java.lang.String,int)>
0:#p#$R$@para0#$I$@para1

<org.apache.hadoop.hbase.avro.generated.ADelete: java.lang.Object get(int)>
0:(= $I$@para0 0)
0:#p#$I$@para0
1:(= $I$@para0 1)
4:#r#$R$@var$stack2
2:#r#$R$@var$stack3

<org.apache.hadoop.hbase.avro.generated.ACompressionAlgorithm: void <clinit>()>
0:#p

<org.apache.hadoop.hbase.avro.generated.AFamilyDescriptor: void <init>()>
0:#p

<org.apache.hadoop.hbase.avro.generated.ADelete: void put(int,java.lang.Object)>
0:(= $I$@para0 0)
0:#p#$I$@para0#$R$@para1
1:(= $I$@para0 1)

<org.apache.hadoop.hbase.avro.generated.AFamilyDescriptor: org.apache.avro.Schema getSchema()>
0:#r#$R$@var$stack1
0:#p

<org.apache.hadoop.hbase.avro.generated.ADelete: void <clinit>()>
0:#p

<org.apache.hadoop.hbase.avro.generated.AGet: void <init>()>
0:#p

<org.apache.hadoop.hbase.avro.generated.AGet: org.apache.avro.Schema getSchema()>
0:#r#$R$@var$stack1
0:#p

<org.apache.hadoop.hbase.avro.generated.AFamilyDescriptor: java.lang.Object get(int)>
0:(= $I$@para0 0)
0:#p#$I$@para0
1:(= $I$@para0 1)
3:(= $I$@para0 2)
7:(= $I$@para0 3)
15:(= $I$@para0 4)
31:(= $I$@para0 5)
63:(= $I$@para0 6)
128:#r#$R$@var$stack3
64:#r#$R$@var$stack4
32:#r#$R$@var$stack5
16:#r#$R$@var$stack6
8:#r#$R$@var$stack7
4:#r#$R$@var$stack8
2:#r#$R$@var$stack2

<org.apache.hadoop.hbase.avro.generated.AGet: java.lang.Object get(int)>
0:(= $I$@para0 0)
0:#p#$I$@para0
1:(= $I$@para0 1)
3:(= $I$@para0 2)
7:(= $I$@para0 3)
15:(= $I$@para0 4)
32:#r#$R$@var$stack3
16:#r#$R$@var$stack4
8:#r#$R$@var$stack5
4:#r#$R$@var$stack6
2:#r#$R$@var$stack2

<org.apache.hadoop.hbase.avro.generated.AGet: void put(int,java.lang.Object)>
0:(= $I$@para0 0)
0:#p#$I$@para0#$R$@para1
1:(= $I$@para0 1)
3:(= $I$@para0 2)
7:(= $I$@para0 3)
15:(= $I$@para0 4)

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: java.lang.Void enableTable(java.nio.ByteBuffer)>
0:#r#soot.jimple.NullConstant@965450422
0:#p#$R$@para0

<org.apache.hadoop.hbase.avro.generated.AGet: void <clinit>()>
0:#p

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: java.lang.Void disableTable(java.nio.ByteBuffer)>
0:#r#soot.jimple.NullConstant@965450422
0:#p#$R$@para0

<org.apache.hadoop.hbase.avro.generated.AIllegalArgument: void <init>()>
0:#p

<org.apache.hadoop.hbase.avro.generated.AFamilyDescriptor: void put(int,java.lang.Object)>
0:(= $I$@para0 0)
0:#p#$I$@para0#$R$@para1
1:(= $I$@para0 1)
3:(= $I$@para0 2)
7:(= $I$@para0 3)
15:(= $I$@para0 4)
31:(= $I$@para0 5)
63:(= $I$@para0 6)

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: java.lang.Void flush(java.nio.ByteBuffer)>
0:#r#soot.jimple.NullConstant@965450422
0:#p#$R$@para0

<org.apache.hadoop.hbase.avro.generated.AFamilyDescriptor: void <clinit>()>
0:#p

<org.apache.hadoop.hbase.avro.generated.AIOError: void <init>()>
0:#p

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: java.lang.Void split(java.nio.ByteBuffer)>
0:#r#soot.jimple.NullConstant@965450422
0:#p#$R$@para0

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: java.lang.Void addFamily(java.nio.ByteBuffer,org.apache.hadoop.hbase.avro.generated.AFamilyDescriptor)>
0:#r#soot.jimple.NullConstant@965450422
0:#p#$R$@para0#$R$@para1

<org.apache.hadoop.hbase.avro.generated.AIOError: org.apache.avro.Schema getSchema()>
0:#r#$R$@var$stack1
0:#p

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: java.lang.Void deleteFamily(java.nio.ByteBuffer,java.nio.ByteBuffer)>
0:#r#soot.jimple.NullConstant@965450422
0:#p#$R$@para0#$R$@para1

<org.apache.hadoop.hbase.avro.generated.AIOError: java.lang.Object get(int)>
0:(= $I$@para0 0)
0:#p#$I$@para0
2:#r#$R$@var$stack2

<org.apache.hadoop.hbase.avro.AvroServer$HBaseImpl: java.lang.Void modifyFamily(java.nio.ByteBuffer,java.nio.ByteBuffer,org.apache.hadoop.hbase.avro.generated.AFamilyDescriptor)>
0:#r#soot.jimple.NullConstant@965450422
0:#p#$R$@para0#$R$@para1#$R$@para2

